---
title: "Class 8: Mini Project"
author: "Elena"
format: gfm
editor: visual
toc: true
---

#Exploring Data

## Preparing Data

```{r}
#Downloaded file from class website and imported into project folder
wisc.df <- read.csv("WisconsinCancer.csv", row.names=1)
head(wisc.df)
```

```{r}
#Removing diagnosis column
wisc.data <- wisc.df[,-1]
head(wisc.data)
```

```{r}
#Saving diagnosis data for later
diagnosis <- as.factor(wisc.df$diagnosis)
head(diagnosis)
```

## Q1. How many observations are in this dataset?

There are 569 observations in the dataset.

```{r}
nrow(wisc.data)
```

## Q2. How many of the observations have a malignant diagnosis?

212 observations have a malignant diagnosis.

```{r}
table(diagnosis)
```

## Q3. How many variables/features in the data are suffixed with \_mean?

10 features in the data are suffixed with \_mean.

```{r}
?grep
length(grep("_mean",colnames(wisc.data)))
```

# PCA

## Performing PCA

Let's try PCA on this data to see what major features might be hidden in this high dimensional data that are hard to see any other way.

Do we need to "scale" this data before PCA? We look at the mean and SD of the variables (i.e. columns)

```{r}
#Check column means and standard deviations
colMeans(wisc.data)
apply(wisc.data,2,sd)
```

```{r}
#Perform PCA on wisc.data
#Scale due to different units
wisc.pr <- prcomp(wisc.data,scale=T)
summary(wisc.pr)
```

```{r}
plot(wisc.pr)
```

## Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

44.27%.

## Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

3.  

## Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

7.  

## Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

One of our main results from methods like PCA is a so-called "score plots," "PC plots," "ordination plots," "PC1 vs PC2," etc.

The base R `biplot()` of the PC data is difficult to understand because it has too much information and labels on it, making it difficult to read and interpret.

```{r}
biplot(wisc.pr)
```

Let's make one of PC1 vs. PC2

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis, xlab="PC1", ylab="PC2")
```

Calculating PC score: SUM(Original Read Counts \* Influence); each sample is then plotted.

## Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

The malignant and benign patients tend to cluster together i.e. share similar characteristics. PC1 vs. PC2 gives a cleaner division between the groups than PC1 vs. PC3, because PC2 captures more variance than PC3.

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=diagnosis, xlab="PC1", ylab="PC3")
```

```{r}
#Graphing with ggplot
library(ggplot2)

# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis

# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point() +
  labs(x="PC1", y="PC2")
```

## Variance

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

## Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr\$rotation\[,1\]) for the feature concave.points_mean? This tells us how much this original feature contributes to the first PC.

-0.26085376.

```{r}
wisc.pr$rotation[,1]
```

# Hierarchical Clustering

```{r}
#Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

```{r}
#Calculate the (Euclidean) distances between all pairs of observations in the new scaled dataset
data.dist <- dist(data.scaled)
```

## Q10. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

Around 19-20.

```{r}
#Create a hierarchical clustering model using complete linkage
wisc.hclust <- hclust(data.dist, method="complete")
plot(wisc.hclust)
abline(h=19.5, col="red", lty=2)
```

## Combine methods

PCA is often used as a first step in further analysis. Here we will combine PCA and clustering.

We have our PCA results in `wisc.pr$x`.

```{r}
wisc.pr.hclust <- hclust( dist(wisc.pr$x[,1:2]), method="ward.D2")
plot(wisc.pr.hclust)
```

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

How do these "grps" i.e. clusters correspond to the expert diagnosis?

```{r}
table(diagnosis, grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
```

```{r}
#install.packages("rgl")
#library(rgl)
#plot3d(wisc.pr$x[,1:3], xlab="PC 1", ylab="PC 2", zlab="PC 3", cex=1.5, size=1, type="s", col=grps)
#rglwidget(width = 400, height = 400)
```

## Q11. OPTIONAL: Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10? How do you judge the quality of your result in each case?

If we cut into increasing number of clusters, we see that some clusters will have better separation of diagnoses (i.e. 0 benign and X number malignant and vice-versa). However, this will also create clusters that have very few samples or have less separation of diagnoses, which can decrease the quality of our results.

```{r}
table(diagnosis, cutree(wisc.pr.hclust, k=2))
table(diagnosis, cutree(wisc.pr.hclust, k=3))
table(diagnosis, cutree(wisc.pr.hclust, k=4))
table(diagnosis, cutree(wisc.pr.hclust, k=5))
table(diagnosis, cutree(wisc.pr.hclust, k=6))
table(diagnosis, cutree(wisc.pr.hclust, k=7))
table(diagnosis, cutree(wisc.pr.hclust, k=8))
table(diagnosis, cutree(wisc.pr.hclust, k=9))
table(diagnosis, cutree(wisc.pr.hclust, k=10))
```

## Q12. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

The "ward.D2" method. With the other methods, the clusters are very unevenly distributed e.g., one patient sample seems to be clustered by itself, away from the other samples. The "ward.D2" method minimizes variance within clusters.

```{r}
wisc.pr.hclust <- hclust( dist(wisc.pr$x[,1:7]), method="single")
plot(wisc.pr.hclust)
```

```{r}
wisc.pr.hclust <- hclust( dist(wisc.pr$x[,1:7]), method="complete")
plot(wisc.pr.hclust)
```

```{r}
wisc.pr.hclust <- hclust( dist(wisc.pr$x[,1:7]), method="average")
plot(wisc.pr.hclust)
```

```{r}
wisc.pr.hclust <- hclust( dist(wisc.pr$x[,1:7]), method="ward.D2")
plot(wisc.pr.hclust)
```

## Q13. How well does the newly created model with four clusters separate out the two diagnoses?

With k=2, the clusters separated the diagnoses fairly well, because most patients within one cluster fell under either the benign or malignant diagnosis. However, with k=4, only 1 and 3 had good separation; 2 and 4 lacked samples and did not have good separation.

```{r}
#Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:7]), method="ward.D2")
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
table(wisc.pr.hclust.clusters, diagnosis)
```

```{r}
#Selecting number of clusters
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters, diagnosis)
```

## Q14. How well do the hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses?

Separation of diagnoses seem to be similar, where one consists of mainly malignant samples and the other consists of mainly benign samples.

```{r}
#Clustering using k-means
km <- kmeans (wisc.data, centers=2)
table(km$cluster, diagnosis)
```

```{r}
#Hierarchical clustering method
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:2]), method="ward.D2")
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
table(wisc.pr.hclust.clusters, diagnosis)
```

## Q15. OPTIONAL: Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

Best sensitivity: hierarchical clustering.

Best specificity: k-means.

```{r}
#Sensitivity = # Samples in predominant malignant cluster / total known malignant samples
#k-means
131/(130+82)
#Hierarchical for first 2 PCs
(18+177)/(177+35)
```

```{r}
#Specificity = # benign samples in predominantly benign cluster / total benign
#k-means
356/(1+356)
#Hierarchical for first 2 PCs
339/(18+339)
```

# Prediction

```{r}
new <- read.csv("https://tinyurl.com/new-samples-CSV")
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=diagnosis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

## Q16. Which of these new patients should we prioritize for follow up based on your results?

Patients that had different diagnoses between the datasets (e.g., benign to malignant, or malignant to benign).
